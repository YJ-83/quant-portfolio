"""
Google Gemini API ê¸°ë°˜ ì£¼ì‹ ë¶„ì„ ëª¨ë“ˆ
ìƒˆë¡œìš´ google-genai íŒ¨í‚¤ì§€ ì‚¬ìš©
í† í° íš¨ìœ¨í™”ë¥¼ ìœ„í•´ ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹± ì ìš©
"""
import os
import time
import re
from typing import Dict, List, Optional
from datetime import datetime

# Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬ (ìƒˆ ë²„ì „)
GEMINI_AVAILABLE = False
GEMINI_NEW_API = False
genai_client = None

try:
    from google import genai
    GEMINI_AVAILABLE = True
    GEMINI_NEW_API = True
    print("[Gemini] google-genai íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ (ìƒˆ API)")
except ImportError:
    try:
        # êµ¬ë²„ì „ fallback
        import google.generativeai as genai_old
        GEMINI_AVAILABLE = True
        GEMINI_NEW_API = False
        print("[Gemini] google.generativeai íŒ¨í‚¤ì§€ ë¡œë“œ ì„±ê³µ (êµ¬ API)")
    except ImportError:
        print("[Gemini] Warning: Gemini íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# ============================================================
# ìºì‹œ ì„¤ì •
# ============================================================
_ANALYSIS_CACHE: Dict[str, Dict] = {}
_CACHE_DURATION = 3600  # 1ì‹œê°„ ìºì‹œ


def _get_api_key_from_secrets() -> Optional[str]:
    """Streamlit Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ"""
    # 1. Streamlit Secrets ì‹œë„ (Streamlit Cloud)
    try:
        import streamlit as st
        if hasattr(st, 'secrets') and 'GEMINI_API_KEY' in st.secrets:
            print("[Gemini] Streamlit Secretsì—ì„œ API í‚¤ ë¡œë“œ")
            return st.secrets['GEMINI_API_KEY']
    except Exception:
        pass

    # 2. í™˜ê²½ë³€ìˆ˜ ì‹œë„
    key = os.getenv('GEMINI_API_KEY')
    if key:
        print("[Gemini] í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ")
        return key

    print("[Gemini] API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    return None


class GeminiAnalyzer:
    """Gemini API ê¸°ë°˜ ì£¼ì‹ ë¶„ì„ê¸°"""

    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Gemini API í‚¤. Noneì´ë©´ Secrets/í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        """
        self.api_key = api_key or _get_api_key_from_secrets()
        self.client = None
        self.initialized = False
        self.use_new_api = False

        self.init_error = None
        self.last_error = None  # ë§ˆì§€ë§‰ API í˜¸ì¶œ ì˜¤ë¥˜

        if self.api_key and GEMINI_AVAILABLE:
            if GEMINI_NEW_API:
                try:
                    # ìƒˆ API ì‹œë„
                    from google import genai
                    self.client = genai.Client(api_key=self.api_key)
                    self.use_new_api = True
                    self.initialized = True
                    print(f"[Gemini] ìƒˆ API ì´ˆê¸°í™” ì„±ê³µ (í‚¤: {self.api_key[:10]}...)")
                except Exception as e1:
                    self.init_error = str(e1)
                    print(f"[Gemini] ìƒˆ API ì´ˆê¸°í™” ì‹¤íŒ¨: {e1}")
            else:
                try:
                    # êµ¬ API
                    import google.generativeai as genai_old
                    genai_old.configure(api_key=self.api_key)
                    self.client = genai_old.GenerativeModel('gemini-1.5-flash')
                    self.use_new_api = False
                    self.initialized = True
                    print(f"[Gemini] êµ¬ API ì´ˆê¸°í™” ì„±ê³µ (í‚¤: {self.api_key[:10]}...)")
                except Exception as e2:
                    self.init_error = str(e2)
                    print(f"[Gemini] êµ¬ API ì´ˆê¸°í™” ì‹¤íŒ¨: {e2}")
        else:
            if not self.api_key:
                self.init_error = "API í‚¤ ì—†ìŒ"
            elif not GEMINI_AVAILABLE:
                self.init_error = "Gemini íŒ¨í‚¤ì§€ ì—†ìŒ"

    def is_available(self) -> bool:
        """Gemini API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return self.initialized and self.client is not None

    def _generate_content(self, prompt: str, max_tokens: int = 150) -> Optional[str]:
        """í†µí•© ì»¨í…ì¸  ìƒì„± - ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„"""
        # ë””ë²„ê¹…: í•¨ìˆ˜ í˜¸ì¶œ ë§ˆì»¤ ì„¤ì •
        self.last_error = "API_CALL_STARTED"
        print("[Gemini] _generate_content ì§„ì…")

        if not self.is_available():
            self.last_error = "API ì‚¬ìš© ë¶ˆê°€"
            return None

        # ì‹œë„í•  ëª¨ë¸ ëª©ë¡ (ìƒˆ google-genai APIëŠ” models/ ì ‘ë‘ì‚¬ í•„ìš”)
        # gemini-2.0-flash-lite: ê°€ì¥ ê°€ë²¼ìš´ 2.0 ëª¨ë¸
        # gemini-1.5-flash: ì•ˆì •ì ì¸ flash ë²„ì „
        models_to_try = [
            'models/gemini-2.0-flash-lite',  # ê°€ì¥ ê°€ë²¼ìš´ 2.0 ëª¨ë¸
            'models/gemini-1.5-flash',       # ì•ˆì •ì ì¸ flash
            'models/gemini-1.5-flash-8b',    # ë” ê°€ë²¼ìš´ flash
            'models/gemini-2.0-flash',       # ìµœì‹  (ì¿¼íƒ€ ì œí•œì )
        ]
        errors = []

        if self.use_new_api:
            # ìƒˆ API - ì—¬ëŸ¬ ëª¨ë¸ ìˆœì°¨ ì‹œë„
            for model_name in models_to_try:
                try:
                    print(f"[Gemini] {model_name} ì‹œë„ ì¤‘...")
                    response = self.client.models.generate_content(
                        model=model_name,
                        contents=prompt,
                        config={
                            'max_output_tokens': max_tokens,
                            'temperature': 0.3
                        }
                    )
                    print(f"[Gemini] {model_name} ì„±ê³µ!")
                    self.last_error = None
                    return response.text
                except Exception as e:
                    error_str = str(e)
                    errors.append(f"{model_name}: {error_str[:100]}")
                    if '429' in error_str or 'RESOURCE_EXHAUSTED' in error_str:
                        print(f"[Gemini] {model_name} ì¿¼íƒ€ ì´ˆê³¼, 2ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ ëª¨ë¸ ì‹œë„...")
                        time.sleep(2)  # Rate limit ëŒ€ê¸°
                        continue  # ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                    elif '404' in error_str or 'NOT_FOUND' in error_str:
                        print(f"[Gemini] {model_name} ëª¨ë¸ ì—†ìŒ, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...")
                        continue
                    else:
                        print(f"[Gemini] {model_name} ì˜¤ë¥˜: {e}")
                        continue  # ë‹¤ë¥¸ ì—ëŸ¬ë„ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
            # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
            self.last_error = " | ".join(errors)
            print(f"[Gemini] ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨: {self.last_error}")
            return None
        else:
            # êµ¬ API
            try:
                response = self.client.generate_content(
                    prompt,
                    generation_config={
                        'max_output_tokens': max_tokens,
                        'temperature': 0.3
                    }
                )
                return response.text
            except Exception as e:
                print(f"[Gemini] êµ¬ API ì˜¤ë¥˜: {e}")
                return None

    def analyze_news_sentiment(self, news_titles: List[str], stock_name: str = "") -> Dict:
        """
        ë‰´ìŠ¤ ì œëª©ë“¤ì˜ ê°ì„± ë¶„ì„ (ë°°ì¹˜ ì²˜ë¦¬ë¡œ í† í° ì ˆì•½)
        """
        if not self.is_available():
            return {'error': 'Gemini API ì‚¬ìš© ë¶ˆê°€', 'sentiment': 'unknown'}

        if not news_titles:
            return {'sentiment': 'neutral', 'score': 0, 'analysis': 'ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤'}

        # ìºì‹œ í‚¤
        cache_key = f"sentiment_{hash(tuple(news_titles[:10]))}"
        if cache_key in _ANALYSIS_CACHE:
            cached = _ANALYSIS_CACHE[cache_key]
            if time.time() - cached['time'] < _CACHE_DURATION:
                return cached['data']

        # í”„ë¡¬í”„íŠ¸ (í† í° ì ˆì•½)
        titles_text = "\n".join([f"- {title[:50]}" for title in news_titles[:10]])

        prompt = f"""ë‹¤ìŒ {stock_name or 'ì£¼ì‹'} ë‰´ìŠ¤ ì œëª©ë“¤ì˜ ê°ì„±ì„ ë¶„ì„í•˜ì„¸ìš”.

{titles_text}

ë‹µë³€ í˜•ì‹:
ê°ì„±: [ê¸ì •/ë¶€ì •/ì¤‘ë¦½]
ì ìˆ˜: [-1.0~1.0]
ìš”ì•½: [í•œ ì¤„]"""

        result_text = self._generate_content(prompt, 100)

        if not result_text:
            return self._fallback_sentiment(news_titles)

        # íŒŒì‹±
        sentiment = 'neutral'
        score = 0.0
        summary = result_text

        if 'ê¸ì •' in result_text:
            sentiment = 'positive'
        elif 'ë¶€ì •' in result_text:
            sentiment = 'negative'

        score_match = re.search(r'ì ìˆ˜[:\s]*([+-]?\d*\.?\d+)', result_text)
        if score_match:
            try:
                score = float(score_match.group(1))
                score = max(-1.0, min(1.0, score))
            except:
                pass

        summary_match = re.search(r'ìš”ì•½[:\s]*(.+?)(?:\n|$)', result_text)
        if summary_match:
            summary = summary_match.group(1).strip()

        result = {
            'sentiment': sentiment,
            'score': score,
            'analysis': summary,
            'news_count': len(news_titles)
        }

        _ANALYSIS_CACHE[cache_key] = {'data': result, 'time': time.time()}
        return result

    def _fallback_sentiment(self, news_titles: List[str]) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ fallback ê°ì„± ë¶„ì„"""
        from data.news_crawler import analyze_news_batch
        news_list = [{'title': t} for t in news_titles]
        batch = analyze_news_batch(news_list)
        return {
            'sentiment': batch['overall_sentiment'],
            'score': (batch['positive_ratio'] - batch['negative_ratio']) / 100,
            'analysis': f"í‚¤ì›Œë“œ ë¶„ì„: ê¸ì • {batch['positive_ratio']:.0f}%, ë¶€ì • {batch['negative_ratio']:.0f}%",
            'is_fallback': True
        }

    def get_stock_recommendation(
        self,
        stock_name: str,
        current_price: float,
        price_change: float,
        technical_signals: Dict,
        news_sentiment: Dict
    ) -> Dict:
        """ì¢…í•© ë§¤ë§¤ ì¶”ì²œ ìƒì„±"""
        # ë””ë²„ê¹…: í•¨ìˆ˜ ì§„ì… ë§ˆì»¤
        self.last_error = "ENTERED_GET_RECOMMENDATION"
        print(f"[Gemini] get_stock_recommendation ì§„ì… - is_available: {self.is_available()}")

        # ìºì‹œ ì™„ì „ ë¹„í™œì„±í™” - ë§¤ë²ˆ API í˜¸ì¶œ ê°•ì œ (ë””ë²„ê¹…ìš©)
        # ìºì‹œ í‚¤ ìƒì„±ë§Œ í•˜ê³ , ì €ì¥/ì¡°íšŒëŠ” í•˜ì§€ ì•ŠìŒ
        cache_key = f"rec_{stock_name}_{datetime.now().strftime('%Y%m%d%H')}"
        # ê¸°ì¡´ ìºì‹œ ì‚­ì œ (fallback ê²°ê³¼ê°€ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŒ)
        if cache_key in _ANALYSIS_CACHE:
            del _ANALYSIS_CACHE[cache_key]

        if not self.is_available():
            self.last_error = "NOT_AVAILABLE_IN_RECOMMENDATION"
            return self._fallback_recommendation(technical_signals, news_sentiment)

        # ê¸°ìˆ ì  ì‹ í˜¸ ìš”ì•½
        tech_summary = self._summarize_technical(technical_signals)

        prompt = f"""ì£¼ì‹ ë¶„ì„:
ì¢…ëª©: {stock_name}
í˜„ì¬ê°€: {current_price:,.0f}ì› ({price_change:+.2f}%)
ê¸°ìˆ ë¶„ì„: {tech_summary}
ë‰´ìŠ¤ê°ì„±: {news_sentiment.get('sentiment', 'ì¤‘ë¦½')}

ë‹µë³€ í˜•ì‹:
ì¶”ì²œ: [ë§¤ìˆ˜/ë§¤ë„/ê´€ë§]
ì‹ ë¢°ë„: [1-5]
ê·¼ê±°: [í•œ ì¤„]"""

        print(f"[Gemini] get_stock_recommendation í˜¸ì¶œ - {stock_name}")

        try:
            result_text = self._generate_content(prompt, 100)
            print(f"[Gemini] _generate_content ê²°ê³¼: {result_text[:50] if result_text else 'None'}")
        except Exception as gen_error:
            self.last_error = f"generate_content ì˜ˆì™¸: {str(gen_error)[:200]}"
            print(f"[Gemini] _generate_content ì˜ˆì™¸ ë°œìƒ: {gen_error}")
            return self._fallback_recommendation(technical_signals, news_sentiment)

        if not result_text:
            print(f"[Gemini] fallbackìœ¼ë¡œ ì „í™˜, last_error: {self.last_error}")
            return self._fallback_recommendation(technical_signals, news_sentiment)

        # íŒŒì‹±
        recommendation = 'ê´€ë§'
        confidence = 3

        if 'ë§¤ìˆ˜' in result_text:
            recommendation = 'ë§¤ìˆ˜'
        elif 'ë§¤ë„' in result_text:
            recommendation = 'ë§¤ë„'

        conf_match = re.search(r'ì‹ ë¢°ë„[:\s]*(\d)', result_text)
        if conf_match:
            confidence = int(conf_match.group(1))
            confidence = max(1, min(5, confidence))

        reason_match = re.search(r'ê·¼ê±°[:\s]*(.+?)(?:\n|$)', result_text, re.DOTALL)
        reason = reason_match.group(1).strip()[:150] if reason_match else result_text[:150]

        result = {
            'recommendation': recommendation,
            'confidence': confidence,
            'reason': reason,
            'timestamp': datetime.now().isoformat()
        }

        # ìºì‹œ ì €ì¥ ë¹„í™œì„±í™” (ë””ë²„ê¹…ìš©)
        # _ANALYSIS_CACHE[cache_key] = {'data': result, 'time': time.time()}
        return result

    def _summarize_technical(self, signals: Dict) -> str:
        """ê¸°ìˆ ì  ì§€í‘œ ìš”ì•½"""
        parts = []
        if 'rsi' in signals:
            rsi = signals['rsi']
            status = 'ê³¼ë§¤ìˆ˜' if rsi > 70 else ('ê³¼ë§¤ë„' if rsi < 30 else 'ì¤‘ë¦½')
            parts.append(f"RSI {rsi:.0f}({status})")
        if 'ma_trend' in signals:
            parts.append(signals['ma_trend'].replace(' ğŸ“ˆ', '').replace(' ğŸ“‰', ''))
        return ", ".join(parts) if parts else "ì •ë³´ì—†ìŒ"

    def _fallback_recommendation(self, technical_signals: Dict, news_sentiment: Dict) -> Dict:
        """ê·œì¹™ ê¸°ë°˜ ì¶”ì²œ"""
        score = 0
        api_error = getattr(self, 'last_error', None)

        # RSI
        rsi = technical_signals.get('rsi', 50)
        if rsi < 30:
            score += 1
        elif rsi > 70:
            score -= 1

        # MACD
        if technical_signals.get('macd', 0) > technical_signals.get('macd_signal', 0):
            score += 0.5
        else:
            score -= 0.5

        # ë‰´ìŠ¤
        sentiment = news_sentiment.get('sentiment', 'neutral')
        if sentiment == 'positive':
            score += 0.5
        elif sentiment == 'negative':
            score -= 0.5

        if score > 0.5:
            recommendation = 'ë§¤ìˆ˜'
        elif score < -0.5:
            recommendation = 'ë§¤ë„'
        else:
            recommendation = 'ê´€ë§'

        reason = 'ê¸°ìˆ ì  ì§€í‘œì™€ ë‰´ìŠ¤ ê°ì„±ì„ ì¢…í•©í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ì„ì…ë‹ˆë‹¤.'
        if api_error:
            reason += f' (API ì˜¤ë¥˜: {api_error[:100]})'

        return {
            'recommendation': recommendation,
            'confidence': 2,
            'reason': reason,
            'is_fallback': True,
            'api_error': api_error,
            'timestamp': datetime.now().isoformat()
        }


def clear_analysis_cache():
    """ë¶„ì„ ìºì‹œ ì´ˆê¸°í™”"""
    global _ANALYSIS_CACHE
    _ANALYSIS_CACHE = {}


# ì‹±ê¸€í†¤
_analyzer_instance: Optional[GeminiAnalyzer] = None


def get_analyzer(api_key: Optional[str] = None) -> GeminiAnalyzer:
    """ë¶„ì„ê¸° ì‹±ê¸€í†¤"""
    global _analyzer_instance
    if _analyzer_instance is None or api_key:
        _analyzer_instance = GeminiAnalyzer(api_key)
    return _analyzer_instance
